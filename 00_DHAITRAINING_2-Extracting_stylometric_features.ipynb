{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokénisation, lemmatisation, étiquetage morphosyntaxique : \n",
    "---\n",
    "\n",
    "**Objectif** : \n",
    "\n",
    "    - Avoir un tableau avec mot / lemme / POS / Oeuvre / Songwriter.\n",
    "    \n",
    "==> Boîte à outils SpaCy : https://spacy.io/api/tokenizer \n",
    "==> https://spacy.io/usage/linguistic-features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Petit focus sur la tokénisation, la lemmatisation et l'étiquetage morpho-syntaxique.\n",
    "\n",
    "   - Qu'est-ce que c'est ?\n",
    "   - Dans quel but faire cela ?\n",
    "   \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e2dbeefe147f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": [
    "# Installation de spacy :\n",
    "\n",
    "# pip install spacy\n",
    "\n",
    "# Librairie pandas (manipulation de données csv, dataframe, etc.)\n",
    "import pandas as pd\n",
    "\n",
    "# Import et lecture du corpus :\n",
    "corpus = pd.read_csv('corpus_nettoye.csv')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fef1d6780d48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorpus_double_chariot_fin_chanson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spacy' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "corpus_double_chariot_fin_chanson=corpus\n",
    "\n",
    "#J'ajoute des \\n à la fin des musiques, c'est utile pour les 3 grams\n",
    "corpus_double_chariot_fin_chanson[\"Lyrics\"]=corpus_double_chariot_fin_chanson[\"Lyrics\"]+\" \\n \"+\"\\n\"\n",
    "\n",
    "#On tokenise les lyrics des chansons \n",
    "corpus_double_chariot_fin_chanson['words'] = corpus_double_chariot_fin_chanson['Lyrics'].apply(lambda x: nlp.tokenizer(str(x)))\n",
    "\n",
    "#J'explose les données \n",
    "\n",
    "corpus_double_chariot_fin_chanson=corpus_double_chariot_fin_chanson.explode(\"words\", ignore_index=True)\n",
    "\n",
    "# À faire : téléchargement du modèle :   \n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Méthode :\n",
    "\n",
    "## Cf. https://stackoverflow.com/questions/44395656/applying-spacy-parser-to-pandas-dataframe-w-multiprocessing\n",
    "\n",
    "## Spacy is highly optimised and does the multiprocessing for you. \n",
    "## As a result, I think your best bet is to take the data out of \n",
    "## the Dataframe and pass it to the Spacy pipeline as a list rather \n",
    "## than trying to use .apply directly.\n",
    "## You then need to the collate the results of the parse, and put \n",
    "## this back into the Dataframe. \n",
    "\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(corpus_double_chariot_fin_chanson['words'].astype('unicode').values, batch_size=50):\n",
    "    if doc.has_annotation(\"DEP\"):\n",
    "        #tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        # tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        \n",
    "# corpus_test['tokens'] = tokens\n",
    "corpus_double_chariot_fin_chanson['lemma'] = lemma\n",
    "corpus_double_chariot_fin_chanson['pos'] = pos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du dataset avec séparation des chansons par le code \"\\n . \\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À faire : téléchargement du modèle :   \n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Méthode :\n",
    "\n",
    "## Cf. https://stackoverflow.com/questions/44395656/applying-spacy-parser-to-pandas-dataframe-w-multiprocessing\n",
    "\n",
    "## Spacy is highly optimised and does the multiprocessing for you. \n",
    "## As a result, I think your best bet is to take the data out of \n",
    "## the Dataframe and pass it to the Spacy pipeline as a list rather \n",
    "## than trying to use .apply directly.\n",
    "## You then need to the collate the results of the parse, and put \n",
    "## this back into the Dataframe. \n",
    "\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(corpus_double_chariot_fin_chanson['words'].astype('unicode').values, batch_size=50):\n",
    "    if doc.has_annotation(\"DEP\"):\n",
    "        #tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        # tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        \n",
    "# corpus_test['tokens'] = tokens\n",
    "corpus_double_chariot_fin_chanson['lemma'] = lemma\n",
    "corpus_double_chariot_fin_chanson['pos'] = pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>Words</td>\n",
       "      <td>[word]</td>\n",
       "      <td>[NOUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>are</td>\n",
       "      <td>[be]</td>\n",
       "      <td>[AUX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>flowing</td>\n",
       "      <td>[flow]</td>\n",
       "      <td>[VERB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>out</td>\n",
       "      <td>[out]</td>\n",
       "      <td>[ADP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>like</td>\n",
       "      <td>[like]</td>\n",
       "      <td>[INTJ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36253</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>hide</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[VERB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36254</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>your</td>\n",
       "      <td>[your]</td>\n",
       "      <td>[PRON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36255</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>love</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[NOUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36256</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>away</td>\n",
       "      <td>[away]</td>\n",
       "      <td>[ADV]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36257</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>\\n \\n</td>\n",
       "      <td>[\\n \\n]</td>\n",
       "      <td>[SPACE]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36258 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                 Song Album Debut  \\\n",
       "0               1                \"Across the Universe\"   Let It Be   \n",
       "1               1                \"Across the Universe\"   Let It Be   \n",
       "2               1                \"Across the Universe\"   Let It Be   \n",
       "3               1                \"Across the Universe\"   Let It Be   \n",
       "4               1                \"Across the Universe\"   Let It Be   \n",
       "...           ...                                  ...         ...   \n",
       "36253         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36254         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36255         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36256         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36257         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "\n",
       "      Songwriter(s) Lead Vocal(s)  Year  \\\n",
       "0            Lennon        Lennon  1968   \n",
       "1            Lennon        Lennon  1968   \n",
       "2            Lennon        Lennon  1968   \n",
       "3            Lennon        Lennon  1968   \n",
       "4            Lennon        Lennon  1968   \n",
       "...             ...           ...   ...   \n",
       "36253        Lennon        Lennon  1965   \n",
       "36254        Lennon        Lennon  1965   \n",
       "36255        Lennon        Lennon  1965   \n",
       "36256        Lennon        Lennon  1965   \n",
       "36257        Lennon        Lennon  1965   \n",
       "\n",
       "                                                  Lyrics    words    lemma  \\\n",
       "0      Words are flowing out like endless rain into a...    Words   [word]   \n",
       "1      Words are flowing out like endless rain into a...      are     [be]   \n",
       "2      Words are flowing out like endless rain into a...  flowing   [flow]   \n",
       "3      Words are flowing out like endless rain into a...      out    [out]   \n",
       "4      Words are flowing out like endless rain into a...     like   [like]   \n",
       "...                                                  ...      ...      ...   \n",
       "36253  Here I stand head in hand Turn my face to the ...     hide   [hide]   \n",
       "36254  Here I stand head in hand Turn my face to the ...     your   [your]   \n",
       "36255  Here I stand head in hand Turn my face to the ...     love   [love]   \n",
       "36256  Here I stand head in hand Turn my face to the ...     away   [away]   \n",
       "36257  Here I stand head in hand Turn my face to the ...    \\n \\n  [\\n \\n]   \n",
       "\n",
       "           pos  \n",
       "0       [NOUN]  \n",
       "1        [AUX]  \n",
       "2       [VERB]  \n",
       "3        [ADP]  \n",
       "4       [INTJ]  \n",
       "...        ...  \n",
       "36253   [VERB]  \n",
       "36254   [PRON]  \n",
       "36255   [NOUN]  \n",
       "36256    [ADV]  \n",
       "36257  [SPACE]  \n",
       "\n",
       "[36258 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regard sur les données : \n",
    "\n",
    "corpus_double_chariot_fin_chanson2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Words are flowing out like endless rain into a paper cup, They slither while they pass, they slip away across the universe. Pools of sorrow, waves of joy are drifting through my opened mind, Possessing and caressing me. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Images of broken light which dance before me like a million eyes, They call me on and on across the universe. Thoughts meander like a restless wind inside a letter box, They tumble blindly as they make their way across the universe. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Sounds of laughter, shades of earth are ringing Through my open ears inciting and inviting me. Limitless, undying love, which shines around me like a million suns, And calls me on and on across the universe. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Jai Guru Deva Jai Guru Deva Jai Guru Deva...\""
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_csv('corpus_nettoye.csv')\n",
    "corpus[\"Lyrics\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Words are flowing out like endless rain into a paper cup, They slither while they pass, they slip away across the universe. Pools of sorrow, waves of joy are drifting through my opened mind, Possessing and caressing me. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Images of broken light which dance before me like a million eyes, They call me on and on across the universe. Thoughts meander like a restless wind inside a letter box, They tumble blindly as they make their way across the universe. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Sounds of laughter, shades of earth are ringing Through my open ears inciting and inviting me. Limitless, undying love, which shines around me like a million suns, And calls me on and on across the universe. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Jai Guru Deva Jai Guru Deva Jai Guru Deva... \\n . \\n\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Words are flowing out like endless rain into a paper cup, They slither while they pass, they slip away across the universe. Pools of sorrow, waves of joy are drifting through my opened mind, Possessing and caressing me. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Images of broken light which dance before me like a million eyes, They call me on and on across the universe. Thoughts meander like a restless wind inside a letter box, They tumble blindly as they make their way across the universe. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Sounds of laughter, shades of earth are ringing Through my open ears inciting and inviting me. Limitless, undying love, which shines around me like a million suns, And calls me on and on across the universe. Jai Guru Deva Om Nothing's gonna change my world, Nothing's gonna change my world. Nothing's gonna change my world, Nothing's gonna change my world. Jai Guru Deva Jai Guru Deva Jai Guru Deva... \\n . \\n\""
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On tokenise les lyrics des chansons \n",
    "corpus_double_chariot_fin_chanson['words'] = corpus_double_chariot_fin_chanson['Lyrics'].apply(lambda x: nlp.tokenizer(str(x)))\n",
    "\n",
    "#J'explose les données \n",
    "\n",
    "corpus_double_chariot_fin_chanson=corpus_double_chariot_fin_chanson.explode(\"words\", ignore_index=True)\n",
    "corpus_double_chariot_fin_chanson[\"Lyrics\"].iloc[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>Words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>flowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36611</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36612</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36613</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36614</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36615</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36616 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                 Song Album Debut  \\\n",
       "0               1                \"Across the Universe\"   Let It Be   \n",
       "1               1                \"Across the Universe\"   Let It Be   \n",
       "2               1                \"Across the Universe\"   Let It Be   \n",
       "3               1                \"Across the Universe\"   Let It Be   \n",
       "4               1                \"Across the Universe\"   Let It Be   \n",
       "...           ...                                  ...         ...   \n",
       "36611         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36612         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36613         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36614         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36615         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "\n",
       "      Songwriter(s) Lead Vocal(s)  Year  \\\n",
       "0            Lennon        Lennon  1968   \n",
       "1            Lennon        Lennon  1968   \n",
       "2            Lennon        Lennon  1968   \n",
       "3            Lennon        Lennon  1968   \n",
       "4            Lennon        Lennon  1968   \n",
       "...             ...           ...   ...   \n",
       "36611        Lennon        Lennon  1965   \n",
       "36612        Lennon        Lennon  1965   \n",
       "36613        Lennon        Lennon  1965   \n",
       "36614        Lennon        Lennon  1965   \n",
       "36615        Lennon        Lennon  1965   \n",
       "\n",
       "                                                  Lyrics    words  \n",
       "0      Words are flowing out like endless rain into a...    Words  \n",
       "1      Words are flowing out like endless rain into a...      are  \n",
       "2      Words are flowing out like endless rain into a...  flowing  \n",
       "3      Words are flowing out like endless rain into a...      out  \n",
       "4      Words are flowing out like endless rain into a...     like  \n",
       "...                                                  ...      ...  \n",
       "36611  Here I stand head in hand Turn my face to the ...     love  \n",
       "36612  Here I stand head in hand Turn my face to the ...     away  \n",
       "36613  Here I stand head in hand Turn my face to the ...      \\n   \n",
       "36614  Here I stand head in hand Turn my face to the ...        .  \n",
       "36615  Here I stand head in hand Turn my face to the ...       \\n  \n",
       "\n",
       "[36616 rows x 8 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_double_chariot_fin_chanson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À faire : téléchargement du modèle :   \n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Méthode :\n",
    "\n",
    "## Cf. https://stackoverflow.com/questions/44395656/applying-spacy-parser-to-pandas-dataframe-w-multiprocessing\n",
    "\n",
    "## Spacy is highly optimised and does the multiprocessing for you. \n",
    "## As a result, I think your best bet is to take the data out of \n",
    "## the Dataframe and pass it to the Spacy pipeline as a list rather \n",
    "## than trying to use .apply directly.\n",
    "## You then need to the collate the results of the parse, and put \n",
    "## this back into the Dataframe. \n",
    "\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(corpus_double_chariot_fin_chanson['words'].astype('unicode').values, batch_size=50):\n",
    "    if doc.has_annotation(\"DEP\"):\n",
    "        #tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        # tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        \n",
    "# corpus_test['tokens'] = tokens\n",
    "corpus_double_chariot_fin_chanson['lemma'] = lemma\n",
    "corpus_double_chariot_fin_chanson['pos'] = pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36614"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation en 3grams :\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "liste_pos = list(corpus_double_chariot_fin_chanson['pos'])\n",
    "three_grams_pos = list(ngrams(liste_pos, 3))\n",
    "three_grams_pos\n",
    "\n",
    "len(three_grams_pos)\n",
    "\n",
    "# Ajout dans la dataframe :\n",
    "# corpus_test['3grams_pos'] = three_grams_pos\n",
    "len(three_grams_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36616"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Différence de longueur entre la df et la liste, ce qui est logique. \n",
    "# Des idées pourquoi ? \n",
    "\n",
    "a = [(['NaN'], ['NaN'], ['NaN'])]\n",
    "b = [(['NaN'], ['NaN'], ['NaN'])]\n",
    "three_grams_pos.extend(a)\n",
    "three_grams_pos.extend(b)\n",
    "\n",
    "len(three_grams_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_double_chariot_fin_chanson['3grams_pos'] = three_grams_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>3grams_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>Words</td>\n",
       "      <td>[word]</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>([NOUN], [AUX], [VERB])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>are</td>\n",
       "      <td>[be]</td>\n",
       "      <td>[AUX]</td>\n",
       "      <td>([AUX], [VERB], [ADP])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>flowing</td>\n",
       "      <td>[flow]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>([VERB], [ADP], [INTJ])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>out</td>\n",
       "      <td>[out]</td>\n",
       "      <td>[ADP]</td>\n",
       "      <td>([ADP], [INTJ], [ADJ])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>like</td>\n",
       "      <td>[like]</td>\n",
       "      <td>[INTJ]</td>\n",
       "      <td>([INTJ], [ADJ], [NOUN])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36611</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>love</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>([NOUN], [ADV], [SPACE])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36612</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>away</td>\n",
       "      <td>[away]</td>\n",
       "      <td>[ADV]</td>\n",
       "      <td>([ADV], [SPACE], [PUNCT])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36613</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[\\n ]</td>\n",
       "      <td>[SPACE]</td>\n",
       "      <td>([SPACE], [PUNCT], [SPACE])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36614</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>.</td>\n",
       "      <td>[.]</td>\n",
       "      <td>[PUNCT]</td>\n",
       "      <td>([NaN], [NaN], [NaN])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36615</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[\\n]</td>\n",
       "      <td>[SPACE]</td>\n",
       "      <td>([NaN], [NaN], [NaN])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36616 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                 Song Album Debut  \\\n",
       "0               1                \"Across the Universe\"   Let It Be   \n",
       "1               1                \"Across the Universe\"   Let It Be   \n",
       "2               1                \"Across the Universe\"   Let It Be   \n",
       "3               1                \"Across the Universe\"   Let It Be   \n",
       "4               1                \"Across the Universe\"   Let It Be   \n",
       "...           ...                                  ...         ...   \n",
       "36611         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36612         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36613         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36614         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36615         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "\n",
       "      Songwriter(s) Lead Vocal(s)  Year  \\\n",
       "0            Lennon        Lennon  1968   \n",
       "1            Lennon        Lennon  1968   \n",
       "2            Lennon        Lennon  1968   \n",
       "3            Lennon        Lennon  1968   \n",
       "4            Lennon        Lennon  1968   \n",
       "...             ...           ...   ...   \n",
       "36611        Lennon        Lennon  1965   \n",
       "36612        Lennon        Lennon  1965   \n",
       "36613        Lennon        Lennon  1965   \n",
       "36614        Lennon        Lennon  1965   \n",
       "36615        Lennon        Lennon  1965   \n",
       "\n",
       "                                                  Lyrics    words   lemma  \\\n",
       "0      Words are flowing out like endless rain into a...    Words  [word]   \n",
       "1      Words are flowing out like endless rain into a...      are    [be]   \n",
       "2      Words are flowing out like endless rain into a...  flowing  [flow]   \n",
       "3      Words are flowing out like endless rain into a...      out   [out]   \n",
       "4      Words are flowing out like endless rain into a...     like  [like]   \n",
       "...                                                  ...      ...     ...   \n",
       "36611  Here I stand head in hand Turn my face to the ...     love  [love]   \n",
       "36612  Here I stand head in hand Turn my face to the ...     away  [away]   \n",
       "36613  Here I stand head in hand Turn my face to the ...      \\n    [\\n ]   \n",
       "36614  Here I stand head in hand Turn my face to the ...        .     [.]   \n",
       "36615  Here I stand head in hand Turn my face to the ...       \\n    [\\n]   \n",
       "\n",
       "           pos                   3grams_pos  \n",
       "0       [NOUN]      ([NOUN], [AUX], [VERB])  \n",
       "1        [AUX]       ([AUX], [VERB], [ADP])  \n",
       "2       [VERB]      ([VERB], [ADP], [INTJ])  \n",
       "3        [ADP]       ([ADP], [INTJ], [ADJ])  \n",
       "4       [INTJ]      ([INTJ], [ADJ], [NOUN])  \n",
       "...        ...                          ...  \n",
       "36611   [NOUN]     ([NOUN], [ADV], [SPACE])  \n",
       "36612    [ADV]    ([ADV], [SPACE], [PUNCT])  \n",
       "36613  [SPACE]  ([SPACE], [PUNCT], [SPACE])  \n",
       "36614  [PUNCT]        ([NaN], [NaN], [NaN])  \n",
       "36615  [SPACE]        ([NaN], [NaN], [NaN])  \n",
       "\n",
       "[36616 rows x 11 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_double_chariot_fin_chanson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_double_chariot_fin_chanson.to_csv('corpus_double_chariot_fin_chanson.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>3grams_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>send</td>\n",
       "      <td>[send]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>([VERB], [ADP], [PRON])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>to</td>\n",
       "      <td>[to]</td>\n",
       "      <td>[ADP]</td>\n",
       "      <td>([ADP], [PRON], [SPACE])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>you</td>\n",
       "      <td>[you]</td>\n",
       "      <td>[PRON]</td>\n",
       "      <td>([PRON], [SPACE], [PUNCT])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[\\n ]</td>\n",
       "      <td>[SPACE]</td>\n",
       "      <td>([SPACE], [PUNCT], [SPACE])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>.</td>\n",
       "      <td>[.]</td>\n",
       "      <td>[PUNCT]</td>\n",
       "      <td>([PUNCT], [SPACE], [NUM])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>\\n</td>\n",
       "      <td>[\\n]</td>\n",
       "      <td>[SPACE]</td>\n",
       "      <td>([SPACE], [NUM], [NUM])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>5</td>\n",
       "      <td>\"All Together Now\"</td>\n",
       "      <td>Yellow Submarine</td>\n",
       "      <td>Lennon-McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1967</td>\n",
       "      <td>One two three four Can I have a little more Fi...</td>\n",
       "      <td>One</td>\n",
       "      <td>[one]</td>\n",
       "      <td>[NUM]</td>\n",
       "      <td>([NUM], [NUM], [NUM])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>5</td>\n",
       "      <td>\"All Together Now\"</td>\n",
       "      <td>Yellow Submarine</td>\n",
       "      <td>Lennon-McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1967</td>\n",
       "      <td>One two three four Can I have a little more Fi...</td>\n",
       "      <td>two</td>\n",
       "      <td>[two]</td>\n",
       "      <td>[NUM]</td>\n",
       "      <td>([NUM], [NUM], [NUM])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>5</td>\n",
       "      <td>\"All Together Now\"</td>\n",
       "      <td>Yellow Submarine</td>\n",
       "      <td>Lennon-McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1967</td>\n",
       "      <td>One two three four Can I have a little more Fi...</td>\n",
       "      <td>three</td>\n",
       "      <td>[three]</td>\n",
       "      <td>[NUM]</td>\n",
       "      <td>([NUM], [NUM], [AUX])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                Song  \\\n",
       "640           3     \"All My Loving\"   \n",
       "641           3     \"All My Loving\"   \n",
       "642           3     \"All My Loving\"   \n",
       "643           3     \"All My Loving\"   \n",
       "644           3     \"All My Loving\"   \n",
       "645           3     \"All My Loving\"   \n",
       "646           5  \"All Together Now\"   \n",
       "647           5  \"All Together Now\"   \n",
       "648           5  \"All Together Now\"   \n",
       "\n",
       "                                      Album Debut     Songwriter(s)  \\\n",
       "640  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "641  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "642  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "643  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "644  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "645  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "646                              Yellow Submarine  Lennon-McCartney   \n",
       "647                              Yellow Submarine  Lennon-McCartney   \n",
       "648                              Yellow Submarine  Lennon-McCartney   \n",
       "\n",
       "    Lead Vocal(s)  Year                                             Lyrics  \\\n",
       "640     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "641     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "642     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "643     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "644     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "645     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "646     McCartney  1967  One two three four Can I have a little more Fi...   \n",
       "647     McCartney  1967  One two three four Can I have a little more Fi...   \n",
       "648     McCartney  1967  One two three four Can I have a little more Fi...   \n",
       "\n",
       "     words    lemma      pos                   3grams_pos  \n",
       "640   send   [send]   [VERB]      ([VERB], [ADP], [PRON])  \n",
       "641     to     [to]    [ADP]     ([ADP], [PRON], [SPACE])  \n",
       "642    you    [you]   [PRON]   ([PRON], [SPACE], [PUNCT])  \n",
       "643    \\n     [\\n ]  [SPACE]  ([SPACE], [PUNCT], [SPACE])  \n",
       "644      .      [.]  [PUNCT]    ([PUNCT], [SPACE], [NUM])  \n",
       "645     \\n     [\\n]  [SPACE]      ([SPACE], [NUM], [NUM])  \n",
       "646    One    [one]    [NUM]        ([NUM], [NUM], [NUM])  \n",
       "647    two    [two]    [NUM]        ([NUM], [NUM], [NUM])  \n",
       "648  three  [three]    [NUM]        ([NUM], [NUM], [AUX])  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_double_chariot_fin_chanson[640:649]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter d'origine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction :\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a Tokenizer with the default settings for English\n",
    "# including punctuation rules and exceptions\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>(Words, are, flowing, out, like, endless, rain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"All I've Got to Do\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1963</td>\n",
       "      <td>Whenever I want you around yeh  All I gotta do...</td>\n",
       "      <td>(Whenever, I, want, you, around, yeh,  , All, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"All My Loving\"</td>\n",
       "      <td>UK: With the Beatles\\n US: Meet the Beatles!</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1963</td>\n",
       "      <td>Close your eyes and I'll kiss you Tomorrow I'l...</td>\n",
       "      <td>(Close, your, eyes, and, I, 'll, kiss, you, To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>\"All Together Now\"</td>\n",
       "      <td>Yellow Submarine</td>\n",
       "      <td>Lennon-McCartney</td>\n",
       "      <td>McCartney</td>\n",
       "      <td>1967</td>\n",
       "      <td>One two three four Can I have a little more Fi...</td>\n",
       "      <td>(One, two, three, four, Can, I, have, a, littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>\"All You Need Is Love\"</td>\n",
       "      <td>Magical Mystery Tour</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1967</td>\n",
       "      <td>Love, love, love Love, love, love Love, love, ...</td>\n",
       "      <td>(Love, ,, love, ,, love, Love, ,, love, ,, lov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    Song  \\\n",
       "0           1   \"Across the Universe\"   \n",
       "1           2    \"All I've Got to Do\"   \n",
       "2           3         \"All My Loving\"   \n",
       "3           5      \"All Together Now\"   \n",
       "4           6  \"All You Need Is Love\"   \n",
       "\n",
       "                                    Album Debut     Songwriter(s)  \\\n",
       "0                                     Let It Be            Lennon   \n",
       "1  UK: With the Beatles\\n US: Meet the Beatles!            Lennon   \n",
       "2  UK: With the Beatles\\n US: Meet the Beatles!         McCartney   \n",
       "3                              Yellow Submarine  Lennon-McCartney   \n",
       "4                          Magical Mystery Tour            Lennon   \n",
       "\n",
       "  Lead Vocal(s)  Year                                             Lyrics  \\\n",
       "0        Lennon  1968  Words are flowing out like endless rain into a...   \n",
       "1        Lennon  1963  Whenever I want you around yeh  All I gotta do...   \n",
       "2     McCartney  1963  Close your eyes and I'll kiss you Tomorrow I'l...   \n",
       "3     McCartney  1967  One two three four Can I have a little more Fi...   \n",
       "4        Lennon  1967  Love, love, love Love, love, love Love, love, ...   \n",
       "\n",
       "                                               words  \n",
       "0  (Words, are, flowing, out, like, endless, rain...  \n",
       "1  (Whenever, I, want, you, around, yeh,  , All, ...  \n",
       "2  (Close, your, eyes, and, I, 'll, kiss, you, To...  \n",
       "3  (One, two, three, four, Can, I, have, a, littl...  \n",
       "4  (Love, ,, love, ,, love, Love, ,, love, ,, lov...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Petit réglage pour permettre d'écrire sur les données...\n",
    "# (sécurité panda)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn' (Cf. https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas)\n",
    "\n",
    "corpus_test = corpus\n",
    "\n",
    "corpus_test['words'] = corpus_test['Lyrics'].apply(lambda x: nlp.tokenizer(str(x)))\n",
    "# df['sents'] = df['text'].apply(lambda x: list(nlp(x).sents))\n",
    "# Réf : https://stackoverflow.com/questions/46981137/tokenizing-using-pandas-and-spacy\n",
    "\n",
    "# Note that nlp by default runs the entire SpaCy pipeline, which includes part-of-speech tagging, parsing and named entity recognition. You can significantly speed up your code by using nlp.tokenizer(x) instead of nlp(x), or by disabling parts of the pipeline when you load the model. E.g. nlp = spacy.load('en', parser=False, entity=False).\n",
    "\n",
    "# Transform data using spaCy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# WARNING: takes a long time!\n",
    "# corpus_test['words'] = corpus_test['Lyrics'].apply(lambda x: [sent.text for sent in nlp(x).sents])\n",
    "\n",
    "corpus_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>Words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>flowing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Song Album Debut Songwriter(s) Lead Vocal(s)  \\\n",
       "0           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "1           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "2           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "3           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "4           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "\n",
       "   Year                                             Lyrics    words  \n",
       "0  1968  Words are flowing out like endless rain into a...    Words  \n",
       "1  1968  Words are flowing out like endless rain into a...      are  \n",
       "2  1968  Words are flowing out like endless rain into a...  flowing  \n",
       "3  1968  Words are flowing out like endless rain into a...      out  \n",
       "4  1968  Words are flowing out like endless rain into a...     like  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://towardsdatascience.com/tokenize-text-columns-into-sentences-in-pandas-2c08bc1ca790\n",
    "corpus_test = corpus_test.explode(\"words\", ignore_index=True)\n",
    "corpus_test.head()\n",
    "# The explode() function is used to transform each element of a list-like to a row, \n",
    "# replicating the index values. Returns: Series- Exploded lists to rows; index will \n",
    "# be duplicated for these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# À faire : téléchargement du modèle :   \n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "## Méthode :\n",
    "\n",
    "## Cf. https://stackoverflow.com/questions/44395656/applying-spacy-parser-to-pandas-dataframe-w-multiprocessing\n",
    "\n",
    "## Spacy is highly optimised and does the multiprocessing for you. \n",
    "## As a result, I think your best bet is to take the data out of \n",
    "## the Dataframe and pass it to the Spacy pipeline as a list rather \n",
    "## than trying to use .apply directly.\n",
    "## You then need to the collate the results of the parse, and put \n",
    "## this back into the Dataframe. \n",
    "\n",
    "lemma = []\n",
    "pos = []\n",
    "\n",
    "for doc in nlp.pipe(corpus_test['words'].astype('unicode').values, batch_size=50):\n",
    "    if doc.has_annotation(\"DEP\"):\n",
    "        #tokens.append([n.text for n in doc])\n",
    "        lemma.append([n.lemma_ for n in doc])\n",
    "        pos.append([n.pos_ for n in doc])\n",
    "    else:\n",
    "        # We want to make sure that the lists of parsed results have the\n",
    "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
    "        # tokens.append(None)\n",
    "        lemma.append(None)\n",
    "        pos.append(None)\n",
    "        \n",
    "# corpus_test['tokens'] = tokens\n",
    "corpus_test['lemma'] = lemma\n",
    "corpus_test['pos'] = pos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>Words</td>\n",
       "      <td>[word]</td>\n",
       "      <td>[NOUN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>are</td>\n",
       "      <td>[be]</td>\n",
       "      <td>[AUX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>flowing</td>\n",
       "      <td>[flow]</td>\n",
       "      <td>[VERB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>out</td>\n",
       "      <td>[out]</td>\n",
       "      <td>[ADP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Across the Universe\"</td>\n",
       "      <td>Let It Be</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1968</td>\n",
       "      <td>Words are flowing out like endless rain into a...</td>\n",
       "      <td>like</td>\n",
       "      <td>[like]</td>\n",
       "      <td>[INTJ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   Song Album Debut Songwriter(s) Lead Vocal(s)  \\\n",
       "0           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "1           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "2           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "3           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "4           1  \"Across the Universe\"   Let It Be        Lennon        Lennon   \n",
       "\n",
       "   Year                                             Lyrics    words   lemma  \\\n",
       "0  1968  Words are flowing out like endless rain into a...    Words  [word]   \n",
       "1  1968  Words are flowing out like endless rain into a...      are    [be]   \n",
       "2  1968  Words are flowing out like endless rain into a...  flowing  [flow]   \n",
       "3  1968  Words are flowing out like endless rain into a...      out   [out]   \n",
       "4  1968  Words are flowing out like endless rain into a...     like  [like]   \n",
       "\n",
       "      pos  \n",
       "0  [NOUN]  \n",
       "1   [AUX]  \n",
       "2  [VERB]  \n",
       "3   [ADP]  \n",
       "4  [INTJ]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regard sur les données : \n",
    "\n",
    "corpus_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c1a12c879acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_test' is not defined"
     ]
    }
   ],
   "source": [
    "corpus_double_chariot_fin_chanson3.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36079"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification qu'il n'y a pas de pb d'alignement entre words / lemma / pos\n",
    "corpus_test.tail()\n",
    "len(corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Transformation en three-grams de POS :\n",
    "\n",
    "   - Pour quoi faire ?\n",
    "   - Voir notamment, sur ce point : ZHAO, Ying, ZOBEL, Justin, « Searching with style : authorship attribution in classic literature », in Proceedings of the thirtieth Australasian conference on Computer science, Volume 62, Australian Computer Society, Inc., AUS, 2007, pp. 59–68.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation en 3grams :\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "liste_pos = list(corpus_test['pos'])\n",
    "three_grams_pos = list(ngrams(liste_pos, 3))\n",
    "three_grams_pos\n",
    "\n",
    "len(three_grams_pos)\n",
    "\n",
    "# Ajout dans la dataframe :\n",
    "# corpus_test['3grams_pos'] = three_grams_pos\n",
    "len(three_grams_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36079"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Différence de longueur entre la df et la liste, ce qui est logique. \n",
    "# Des idées pourquoi ? \n",
    "\n",
    "a = [(['NOUN'], ['ADV'], ['NaN'])]\n",
    "b = [(['ADV'], ['NaN'], ['NaN'])]\n",
    "three_grams_pos.extend(a)\n",
    "three_grams_pos.extend(b)\n",
    "\n",
    "len(three_grams_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test['3grams_pos'] = three_grams_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Song</th>\n",
       "      <th>Album Debut</th>\n",
       "      <th>Songwriter(s)</th>\n",
       "      <th>Lead Vocal(s)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>words</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>3grams_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36074</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>to</td>\n",
       "      <td>[to]</td>\n",
       "      <td>[ADP]</td>\n",
       "      <td>([ADP], [VERB], [PRON])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36075</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>hide</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[VERB]</td>\n",
       "      <td>([VERB], [PRON], [NOUN])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36076</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>your</td>\n",
       "      <td>[your]</td>\n",
       "      <td>[PRON]</td>\n",
       "      <td>([PRON], [NOUN], [ADV])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36077</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>love</td>\n",
       "      <td>[love]</td>\n",
       "      <td>[NOUN]</td>\n",
       "      <td>([NOUN], [ADV], [NaN])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36078</th>\n",
       "      <td>217</td>\n",
       "      <td>\"You've Got to Hide Your Love Away\"</td>\n",
       "      <td>Help!</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>Lennon</td>\n",
       "      <td>1965</td>\n",
       "      <td>Here I stand head in hand Turn my face to the ...</td>\n",
       "      <td>away</td>\n",
       "      <td>[away]</td>\n",
       "      <td>[ADV]</td>\n",
       "      <td>([ADV], [NaN], [NaN])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                 Song Album Debut  \\\n",
       "36074         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36075         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36076         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36077         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "36078         217  \"You've Got to Hide Your Love Away\"       Help!   \n",
       "\n",
       "      Songwriter(s) Lead Vocal(s)  Year  \\\n",
       "36074        Lennon        Lennon  1965   \n",
       "36075        Lennon        Lennon  1965   \n",
       "36076        Lennon        Lennon  1965   \n",
       "36077        Lennon        Lennon  1965   \n",
       "36078        Lennon        Lennon  1965   \n",
       "\n",
       "                                                  Lyrics words   lemma  \\\n",
       "36074  Here I stand head in hand Turn my face to the ...    to    [to]   \n",
       "36075  Here I stand head in hand Turn my face to the ...  hide  [hide]   \n",
       "36076  Here I stand head in hand Turn my face to the ...  your  [your]   \n",
       "36077  Here I stand head in hand Turn my face to the ...  love  [love]   \n",
       "36078  Here I stand head in hand Turn my face to the ...  away  [away]   \n",
       "\n",
       "          pos                3grams_pos  \n",
       "36074   [ADP]   ([ADP], [VERB], [PRON])  \n",
       "36075  [VERB]  ([VERB], [PRON], [NOUN])  \n",
       "36076  [PRON]   ([PRON], [NOUN], [ADV])  \n",
       "36077  [NOUN]    ([NOUN], [ADV], [NaN])  \n",
       "36078   [ADV]     ([ADV], [NaN], [NaN])  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde en csv :\n",
    "\n",
    "corpus_test.to_csv('corpus_tokmorph.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python37564bitbasecondaa50c3607aaec4d41a1290a133b998fce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
